[
  {
    "objectID": "homework8.html",
    "href": "homework8.html",
    "title": "HomeWork8",
    "section": "",
    "text": "When you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'dials' was built under R version 4.4.2\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.2\n\n\nWarning: package 'recipes' was built under R version 4.4.2\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.2\n\n\nWarning: package 'workflows' was built under R version 4.4.2\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.4.2\n\nlibrary(dplyr)\n\n#bike_data &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\")\n\nAs the above code gave the error I found the solution on the google as follows\n\nurl &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\"\nbike_data &lt;- read.csv(url, fileEncoding = \"latin1\")\n\n# Check the data\nhead(bike_data)\n\n        Date Rented.Bike.Count Hour Temperature..C. Humidity...\n1 01/12/2017               254    0            -5.2          37\n2 01/12/2017               204    1            -5.5          38\n3 01/12/2017               173    2            -6.0          39\n4 01/12/2017               107    3            -6.2          40\n5 01/12/2017                78    4            -6.0          36\n6 01/12/2017               100    5            -6.4          37\n  Wind.speed..m.s. Visibility..10m. Dew.point.temperature..C.\n1              2.2             2000                     -17.6\n2              0.8             2000                     -17.6\n3              1.0             2000                     -17.7\n4              0.9             2000                     -17.6\n5              2.3             2000                     -18.6\n6              1.5             2000                     -18.7\n  Solar.Radiation..MJ.m2. Rainfall.mm. Snowfall..cm. Seasons    Holiday\n1                       0            0             0  Winter No Holiday\n2                       0            0             0  Winter No Holiday\n3                       0            0             0  Winter No Holiday\n4                       0            0             0  Winter No Holiday\n5                       0            0             0  Winter No Holiday\n6                       0            0             0  Winter No Holiday\n  Functioning.Day\n1             Yes\n2             Yes\n3             Yes\n4             Yes\n5             Yes\n6             Yes\n\n\nNotice: The korean Character in temperature Let’s check the structure first and then we can clean up the data\n\nstr(bike_data)\n\n'data.frame':   8760 obs. of  14 variables:\n $ Date                     : chr  \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented.Bike.Count        : int  254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                     : int  0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature..C.          : num  -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity...              : int  37 38 39 40 36 37 35 38 37 27 ...\n $ Wind.speed..m.s.         : num  2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility..10m.         : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 1928 ...\n $ Dew.point.temperature..C.: num  -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar.Radiation..MJ.m2.  : num  0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall.mm.             : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall..cm.            : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                  : chr  \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                  : chr  \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning.Day          : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n\n\nNow we notice a few things that need to be cleaned up:\n\nThe temperature columns have Korean characters in their names\nThe Date column is in character format\nSome columns should be factors (Seasons, Holiday, Functioning Day)\n\n\n# Clean and rename the data\nbike_data_clean &lt;- bike_data %&gt;%\n    rename(\n    date = Date,\n    bike_count = `Rented.Bike.Count`,\n    hour = Hour,\n    temperature = `Temperature..C.`,\n    humidity = `Humidity...`,\n    wind_speed = `Wind.speed..m.s.`,\n    visibility = `Visibility..10m.`,\n    dew_point = `Dew.point.temperature..C.`,\n    solar_radiation = `Solar.Radiation..MJ.m2.`,\n    rainfall = `Rainfall.mm.`,\n    snowfall = `Snowfall..cm.`,\n    seasons = Seasons,\n    holiday = Holiday,\n    functioning_day = `Functioning.Day`\n  )"
  },
  {
    "objectID": "homework8.html#reading-the-data",
    "href": "homework8.html#reading-the-data",
    "title": "HomeWork8",
    "section": "",
    "text": "When you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'dials' was built under R version 4.4.2\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.2\n\n\nWarning: package 'recipes' was built under R version 4.4.2\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.2\n\n\nWarning: package 'workflows' was built under R version 4.4.2\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.4.2\n\nlibrary(dplyr)\n\n#bike_data &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\")\n\nAs the above code gave the error I found the solution on the google as follows\n\nurl &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\"\nbike_data &lt;- read.csv(url, fileEncoding = \"latin1\")\n\n# Check the data\nhead(bike_data)\n\n        Date Rented.Bike.Count Hour Temperature..C. Humidity...\n1 01/12/2017               254    0            -5.2          37\n2 01/12/2017               204    1            -5.5          38\n3 01/12/2017               173    2            -6.0          39\n4 01/12/2017               107    3            -6.2          40\n5 01/12/2017                78    4            -6.0          36\n6 01/12/2017               100    5            -6.4          37\n  Wind.speed..m.s. Visibility..10m. Dew.point.temperature..C.\n1              2.2             2000                     -17.6\n2              0.8             2000                     -17.6\n3              1.0             2000                     -17.7\n4              0.9             2000                     -17.6\n5              2.3             2000                     -18.6\n6              1.5             2000                     -18.7\n  Solar.Radiation..MJ.m2. Rainfall.mm. Snowfall..cm. Seasons    Holiday\n1                       0            0             0  Winter No Holiday\n2                       0            0             0  Winter No Holiday\n3                       0            0             0  Winter No Holiday\n4                       0            0             0  Winter No Holiday\n5                       0            0             0  Winter No Holiday\n6                       0            0             0  Winter No Holiday\n  Functioning.Day\n1             Yes\n2             Yes\n3             Yes\n4             Yes\n5             Yes\n6             Yes\n\n\nNotice: The korean Character in temperature Let’s check the structure first and then we can clean up the data\n\nstr(bike_data)\n\n'data.frame':   8760 obs. of  14 variables:\n $ Date                     : chr  \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented.Bike.Count        : int  254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                     : int  0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature..C.          : num  -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity...              : int  37 38 39 40 36 37 35 38 37 27 ...\n $ Wind.speed..m.s.         : num  2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility..10m.         : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 1928 ...\n $ Dew.point.temperature..C.: num  -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar.Radiation..MJ.m2.  : num  0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall.mm.             : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall..cm.            : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                  : chr  \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                  : chr  \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning.Day          : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n\n\nNow we notice a few things that need to be cleaned up:\n\nThe temperature columns have Korean characters in their names\nThe Date column is in character format\nSome columns should be factors (Seasons, Holiday, Functioning Day)\n\n\n# Clean and rename the data\nbike_data_clean &lt;- bike_data %&gt;%\n    rename(\n    date = Date,\n    bike_count = `Rented.Bike.Count`,\n    hour = Hour,\n    temperature = `Temperature..C.`,\n    humidity = `Humidity...`,\n    wind_speed = `Wind.speed..m.s.`,\n    visibility = `Visibility..10m.`,\n    dew_point = `Dew.point.temperature..C.`,\n    solar_radiation = `Solar.Radiation..MJ.m2.`,\n    rainfall = `Rainfall.mm.`,\n    snowfall = `Snowfall..cm.`,\n    seasons = Seasons,\n    holiday = Holiday,\n    functioning_day = `Functioning.Day`\n  )"
  },
  {
    "objectID": "homework8.html#eda",
    "href": "homework8.html#eda",
    "title": "HomeWork8",
    "section": "EDA",
    "text": "EDA\n\nChecking the Data\n\nCheck for missingness: In this first step we should check any missing data from the different variables.\n\n\n# 1. Check for missingness\nmissing_summary &lt;- colSums(is.na(bike_data_clean))\nprint(\"Missing values in each column:\")\n\n[1] \"Missing values in each column:\"\n\nprint(missing_summary)\n\n           date      bike_count            hour     temperature        humidity \n              0               0               0               0               0 \n     wind_speed      visibility       dew_point solar_radiation        rainfall \n              0               0               0               0               0 \n       snowfall         seasons         holiday functioning_day \n              0               0               0               0 \n\n\nWe have no missing values in any column of our dataset. This makes our analysis much simpler since we don’t need to handle missing data imputation.\n\nCheck the column types and the values within the columns to make sure they make sense (basic summary stats for numeric columns and check the unique values for the categorical variables).\n\n\n# 1. First, let's look at the structure of our data\nstr(bike_data_clean)\n\n'data.frame':   8760 obs. of  14 variables:\n $ date           : chr  \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ bike_count     : int  254 204 173 107 78 100 181 460 930 490 ...\n $ hour           : int  0 1 2 3 4 5 6 7 8 9 ...\n $ temperature    : num  -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ humidity       : int  37 38 39 40 36 37 35 38 37 27 ...\n $ wind_speed     : num  2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ visibility     : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 1928 ...\n $ dew_point      : num  -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ solar_radiation: num  0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ rainfall       : num  0 0 0 0 0 0 0 0 0 0 ...\n $ snowfall       : num  0 0 0 0 0 0 0 0 0 0 ...\n $ seasons        : chr  \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ holiday        : chr  \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ functioning_day: chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n\n# 2. Summary statistics for numeric columns\nsummary(bike_data_clean %&gt;% select_if(is.numeric))\n\n   bike_count          hour        temperature        humidity    \n Min.   :   0.0   Min.   : 0.00   Min.   :-17.80   Min.   : 0.00  \n 1st Qu.: 191.0   1st Qu.: 5.75   1st Qu.:  3.50   1st Qu.:42.00  \n Median : 504.5   Median :11.50   Median : 13.70   Median :57.00  \n Mean   : 704.6   Mean   :11.50   Mean   : 12.88   Mean   :58.23  \n 3rd Qu.:1065.2   3rd Qu.:17.25   3rd Qu.: 22.50   3rd Qu.:74.00  \n Max.   :3556.0   Max.   :23.00   Max.   : 39.40   Max.   :98.00  \n   wind_speed      visibility     dew_point       solar_radiation \n Min.   :0.000   Min.   :  27   Min.   :-30.600   Min.   :0.0000  \n 1st Qu.:0.900   1st Qu.: 940   1st Qu.: -4.700   1st Qu.:0.0000  \n Median :1.500   Median :1698   Median :  5.100   Median :0.0100  \n Mean   :1.725   Mean   :1437   Mean   :  4.074   Mean   :0.5691  \n 3rd Qu.:2.300   3rd Qu.:2000   3rd Qu.: 14.800   3rd Qu.:0.9300  \n Max.   :7.400   Max.   :2000   Max.   : 27.200   Max.   :3.5200  \n    rainfall          snowfall      \n Min.   : 0.0000   Min.   :0.00000  \n 1st Qu.: 0.0000   1st Qu.:0.00000  \n Median : 0.0000   Median :0.00000  \n Mean   : 0.1487   Mean   :0.07507  \n 3rd Qu.: 0.0000   3rd Qu.:0.00000  \n Max.   :35.0000   Max.   :8.80000  \n\n# 3. Unique values for categorical variables\ncat(\"\\nUnique values in Seasons:\\n\")\n\n\nUnique values in Seasons:\n\nunique(bike_data_clean$seasons)\n\n[1] \"Winter\" \"Spring\" \"Summer\" \"Autumn\"\n\ncat(\"\\nUnique values in Holiday:\\n\")\n\n\nUnique values in Holiday:\n\nunique(bike_data_clean$holiday)\n\n[1] \"No Holiday\" \"Holiday\"   \n\ncat(\"\\nUnique values in Functioning Day:\\n\")\n\n\nUnique values in Functioning Day:\n\nunique(bike_data_clean$functioning_day)\n\n[1] \"Yes\" \"No\" \n\n# 4. Range checks for numeric variables\nnumeric_ranges &lt;- sapply(bike_data_clean %&gt;% select_if(is.numeric), range)\ncat(\"\\nRanges for numeric variables:\\n\")\n\n\nRanges for numeric variables:\n\nprint(numeric_ranges)\n\n     bike_count hour temperature humidity wind_speed visibility dew_point\n[1,]          0    0       -17.8        0        0.0         27     -30.6\n[2,]       3556   23        39.4       98        7.4       2000      27.2\n     solar_radiation rainfall snowfall\n[1,]            0.00        0      0.0\n[2,]            3.52       35      8.8\n\n# 5. Check if values make sense\n# For example, check if hour is between 0-23\ncat(\"\\nHour range check:\", \n    min(bike_data_clean$hour), \"to\", max(bike_data_clean$hour))\n\n\nHour range check: 0 to 23\n\n# Check if humidity is between 0-100\ncat(\"\\nHumidity range check:\", \n    min(bike_data_clean$humidity), \"to\", max(bike_data_clean$humidity))\n\n\nHumidity range check: 0 to 98\n\n# 6. Date range check\ncat(\"\\nDate range:\", \n    min(bike_data_clean$date), \"to\", max(bike_data_clean$date))\n\n\nDate range: 01/01/2018 to 31/12/2017\n\n# 7. Frequency table for categorical variables\ncat(\"\\nFrequency table for Seasons:\\n\")\n\n\nFrequency table for Seasons:\n\ntable(bike_data_clean$seasons)\n\n\nAutumn Spring Summer Winter \n  2184   2208   2208   2160 \n\ncat(\"\\nFrequency table for Holiday:\\n\")\n\n\nFrequency table for Holiday:\n\ntable(bike_data_clean$holiday)\n\n\n   Holiday No Holiday \n       432       8328 \n\ncat(\"\\nFrequency table for Functioning Day:\\n\")\n\n\nFrequency table for Functioning Day:\n\ntable(bike_data_clean$functioning_day)\n\n\n  No  Yes \n 295 8465 \n\n# 8. Check for any impossible values\nimpossible_values &lt;- data.frame(\n  negative_bikes = sum(bike_data_clean$bike_count &lt; 0),\n  humidity_over_100 = sum(bike_data_clean$humidity &gt; 100),\n  negative_temp = sum(bike_data_clean$temperature &lt; -50),  # Unreasonable temp\n  negative_wind = sum(bike_data_clean$wind_speed &lt; 0),\n  negative_visibility = sum(bike_data_clean$visibility &lt; 0)\n)\n\ncat(\"\\nCheck for impossible values:\\n\")\n\n\nCheck for impossible values:\n\nprint(impossible_values)\n\n  negative_bikes humidity_over_100 negative_temp negative_wind\n1              0                 0             0             0\n  negative_visibility\n1                   0\n\n\nLooks good! No impossible values\n\nConvert the Date column into an actual date (if need be). Recall the lubridate package.\n\n\nhead(bike_data_clean$date)\n\n[1] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\"\n[6] \"01/12/2017\"\n\nbike_data_clean &lt;- bike_data_clean %&gt;%\n  mutate(date = dmy(date))  # dmy because original format was \"DD/MM/YYYY\"\n\n# Verify the conversion\ncat(\"\\nClass after conversion:\", class(bike_data_clean$date))\n\n\nClass after conversion: Date\n\n# Look at first few dates to verify format\ncat(\"\\n\\nFirst few dates:\")\n\n\n\nFirst few dates:\n\nhead(bike_data_clean$date)\n\n[1] \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" \"2017-12-01\"\n[6] \"2017-12-01\"\n\n\n\nTurn the character variables (Seasons, Holiday, and Functioning Day) into factors.\n\n\n# 4. Convert character variables to factors\nbike_data_clean &lt;- bike_data_clean %&gt;%\n  mutate(across(c(seasons, holiday, functioning_day), as.factor))\n\n# Verify the conversion\nstr(bike_data_clean$seasons)\n\n Factor w/ 4 levels \"Autumn\",\"Spring\",..: 4 4 4 4 4 4 4 4 4 4 ...\n\nstr(bike_data_clean$holiday)\n\n Factor w/ 2 levels \"Holiday\",\"No Holiday\": 2 2 2 2 2 2 2 2 2 2 ...\n\nstr(bike_data_clean$functioning_day)\n\n Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n\n# Check unique values in each factor\ncat(\"\\nUnique values in seasons:\\n\")\n\n\nUnique values in seasons:\n\nunique(bike_data_clean$seasons)\n\n[1] Winter Spring Summer Autumn\nLevels: Autumn Spring Summer Winter\n\ncat(\"\\nUnique values in holiday:\\n\")\n\n\nUnique values in holiday:\n\nunique(bike_data_clean$holiday)\n\n[1] No Holiday Holiday   \nLevels: Holiday No Holiday\n\ncat(\"\\nUnique values in functioning_day:\\n\")\n\n\nUnique values in functioning_day:\n\nunique(bike_data_clean$functioning_day)\n\n[1] Yes No \nLevels: No Yes\n\n\n\nLastly, rename the all the variables to have easy to use names - This step is already performed.\nCreate summary statistics (especially related to the bike rental count). These should be done across your categorical variables as well. You should notice something about the Functioning Day variable. Subset the data appropriately based on that.\n\n\n# Overall summary of bike rentals\ncat(\"Overall bike rental summary:\\n\")\n\nOverall bike rental summary:\n\nsummary(bike_data_clean$bike_count)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0   191.0   504.5   704.6  1065.2  3556.0 \n\n# Summary by Functioning Day\ncat(\"\\nBike rentals by Functioning Day:\\n\")\n\n\nBike rentals by Functioning Day:\n\nbike_data_clean %&gt;%\n  group_by(functioning_day) %&gt;%\n  summarise(\n    n = n(),\n    mean_rentals = mean(bike_count),\n    sd_rentals = sd(bike_count),\n    median_rentals = median(bike_count),\n    min_rentals = min(bike_count),\n    max_rentals = max(bike_count)\n  )\n\n# A tibble: 2 × 7\n  functioning_day     n mean_rentals sd_rentals median_rentals min_rentals\n  &lt;fct&gt;           &lt;int&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;int&gt;       &lt;int&gt;\n1 No                295           0          0               0           0\n2 Yes              8465         729.       642.            542           2\n# ℹ 1 more variable: max_rentals &lt;int&gt;\n\n\nSince there are zero rentals on non-functioning days, we should subset our data to only include functioning days:\n\n# Subset to only functioning days\nbike_data_clean &lt;- bike_data_clean %&gt;%\n  filter(functioning_day == \"Yes\")\n\n# Verify the subsetting\ncat(\"Number of observations after filtering:\", nrow(bike_data_clean), \"\\n\")\n\nNumber of observations after filtering: 8465 \n\n# Now let's look at the summary statistics for our filtered dataset\nbike_summary &lt;- bike_data_clean %&gt;%\n  summarise(\n    n = n(),\n    mean_rentals = mean(bike_count),\n    sd_rentals = sd(bike_count),\n    median_rentals = median(bike_count),\n    min_rentals = min(bike_count),\n    max_rentals = max(bike_count)\n  )\n\nprint(bike_summary)\n\n     n mean_rentals sd_rentals median_rentals min_rentals max_rentals\n1 8465      729.157   642.3512            542           2        3556\n\n# Let's also look at rentals by season and holiday status in our filtered dataset\ncat(\"\\nBike rentals by season (functioning days only):\\n\")\n\n\nBike rentals by season (functioning days only):\n\nbike_data_clean %&gt;%\n  group_by(seasons) %&gt;%\n  summarise(\n    n = n(),\n    mean_rentals = mean(bike_count),\n    sd_rentals = sd(bike_count),\n    median_rentals = median(bike_count),\n    min_rentals = min(bike_count),\n    max_rentals = max(bike_count)\n  )\n\n# A tibble: 4 × 7\n  seasons     n mean_rentals sd_rentals median_rentals min_rentals max_rentals\n  &lt;fct&gt;   &lt;int&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;int&gt;       &lt;int&gt;\n1 Autumn   1937         924.       618.           856            2        3298\n2 Spring   2160         746.       619.           599            2        3251\n3 Summer   2208        1034.       690.           906.           9        3556\n4 Winter   2160         226.       150.           203            3         937\n\ncat(\"\\nBike rentals by holiday status (functioning days only):\\n\")\n\n\nBike rentals by holiday status (functioning days only):\n\nbike_data_clean %&gt;%\n  group_by(holiday) %&gt;%\n  summarise(\n    n = n(),\n    mean_rentals = mean(bike_count),\n    sd_rentals = sd(bike_count),\n    median_rentals = median(bike_count),\n    min_rentals = min(bike_count),\n    max_rentals = max(bike_count)\n  )\n\n# A tibble: 2 × 7\n  holiday       n mean_rentals sd_rentals median_rentals min_rentals max_rentals\n  &lt;fct&gt;     &lt;int&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;int&gt;       &lt;int&gt;\n1 Holiday     408         529.       574.            259           3        2400\n2 No Holid…  8057         739.       644.            561           2        3556\n\n\n\nTo simplify our analysis, we’ll summarize across the hours so that each day has one observation associated with it. • Let’s group_by() the date, seasons, and holiday variables. • Find the sum of the bike_count, rainfall, and snowfall variables • Find the mean of all the weather related variables. • This will be our new data that we’ll analyze!\n\n\ndaily_bike_data &lt;- bike_data_clean %&gt;%\n  group_by(date, seasons, holiday) %&gt;%\n  summarise(\n    # Sum variables\n    total_bikes = sum(bike_count),\n    total_rainfall = sum(rainfall),\n    total_snowfall = sum(snowfall),\n    \n    # Mean of weather variables\n    mean_temp = mean(temperature),\n    mean_humidity = mean(humidity),\n    mean_wind_speed = mean(wind_speed),\n    mean_visibility = mean(visibility),\n    mean_dew_point = mean(dew_point),\n    mean_solar_rad = mean(solar_radiation),\n    .groups = 'drop'  # This drops the grouping after summarise\n  )\n\n# Look at the structure of our new dataset\nstr(daily_bike_data)\n\ntibble [353 × 12] (S3: tbl_df/tbl/data.frame)\n $ date           : Date[1:353], format: \"2017-12-01\" \"2017-12-02\" ...\n $ seasons        : Factor w/ 4 levels \"Autumn\",\"Spring\",..: 4 4 4 4 4 4 4 4 4 4 ...\n $ holiday        : Factor w/ 2 levels \"Holiday\",\"No Holiday\": 2 2 2 2 2 2 2 2 2 2 ...\n $ total_bikes    : int [1:353] 9539 8523 7222 8729 8307 6669 8549 8032 7233 3453 ...\n $ total_rainfall : num [1:353] 0 0 4 0.1 0 1.3 0 0 0 4.1 ...\n $ total_snowfall : num [1:353] 0 0 0 0 0 8.6 10.4 0 0 32.5 ...\n $ mean_temp      : num [1:353] -2.454 1.325 4.875 -0.304 -4.458 ...\n $ mean_humidity  : num [1:353] 45.9 62 81.5 52.5 36.4 ...\n $ mean_wind_speed: num [1:353] 1.54 1.71 1.61 3.45 1.11 ...\n $ mean_visibility: num [1:353] 1871 1471 456 1363 1959 ...\n $ mean_dew_point : num [1:353] -13.55 -5.72 1.88 -9.93 -17.43 ...\n $ mean_solar_rad : num [1:353] 0.2487 0.2637 0.1254 0.2829 0.0358 ...\n\n# View first few rows\nhead(daily_bike_data)\n\n# A tibble: 6 × 12\n  date       seasons holiday total_bikes total_rainfall total_snowfall mean_temp\n  &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;         &lt;int&gt;          &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1 2017-12-01 Winter  No Hol…        9539            0              0     -2.45  \n2 2017-12-02 Winter  No Hol…        8523            0              0      1.32  \n3 2017-12-03 Winter  No Hol…        7222            4              0      4.88  \n4 2017-12-04 Winter  No Hol…        8729            0.1            0     -0.304 \n5 2017-12-05 Winter  No Hol…        8307            0              0     -4.46  \n6 2017-12-06 Winter  No Hol…        6669            1.3            8.6    0.0458\n# ℹ 5 more variables: mean_humidity &lt;dbl&gt;, mean_wind_speed &lt;dbl&gt;,\n#   mean_visibility &lt;dbl&gt;, mean_dew_point &lt;dbl&gt;, mean_solar_rad &lt;dbl&gt;\n\n# Basic summary statistics of our new daily data\nsummary(daily_bike_data)\n\n      date              seasons         holiday     total_bikes   \n Min.   :2017-12-01   Autumn:81   Holiday   : 17   Min.   :  977  \n 1st Qu.:2018-02-27   Spring:90   No Holiday:336   1st Qu.: 6967  \n Median :2018-05-28   Summer:92                    Median :18563  \n Mean   :2018-05-28   Winter:90                    Mean   :17485  \n 3rd Qu.:2018-08-24                                3rd Qu.:26285  \n Max.   :2018-11-30                                Max.   :36149  \n total_rainfall   total_snowfall     mean_temp       mean_humidity  \n Min.   : 0.000   Min.   : 0.000   Min.   :-14.738   Min.   :22.25  \n 1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.:  3.304   1st Qu.:47.58  \n Median : 0.000   Median : 0.000   Median : 13.738   Median :57.17  \n Mean   : 3.576   Mean   : 1.863   Mean   : 12.776   Mean   :58.17  \n 3rd Qu.: 0.500   3rd Qu.: 0.000   3rd Qu.: 22.592   3rd Qu.:67.71  \n Max.   :95.500   Max.   :78.700   Max.   : 33.742   Max.   :95.88  \n mean_wind_speed  mean_visibility  mean_dew_point    mean_solar_rad   \n Min.   :0.6625   Min.   : 214.3   Min.   :-27.750   Min.   :0.02917  \n 1st Qu.:1.3042   1st Qu.:1087.0   1st Qu.: -5.188   1st Qu.:0.28333  \n Median :1.6583   Median :1557.8   Median :  4.612   Median :0.56500  \n Mean   :1.7261   Mean   :1434.0   Mean   :  3.954   Mean   :0.56773  \n 3rd Qu.:1.9542   3rd Qu.:1874.3   3rd Qu.: 14.921   3rd Qu.:0.82000  \n Max.   :4.0000   Max.   :2000.0   Max.   : 25.038   Max.   :1.21667  \n\n# Check number of daily observations\ncat(\"\\nNumber of daily observations:\", nrow(daily_bike_data))\n\n\nNumber of daily observations: 353\n\n# Quick summary by season\ndaily_bike_data %&gt;%\n  group_by(seasons) %&gt;%\n  summarise(\n    n_days = n(),\n    mean_daily_rentals = mean(total_bikes),\n    sd_daily_rentals = sd(total_bikes)\n  )\n\n# A tibble: 4 × 4\n  seasons n_days mean_daily_rentals sd_daily_rentals\n  &lt;fct&gt;    &lt;int&gt;              &lt;dbl&gt;            &lt;dbl&gt;\n1 Autumn      81             22099.            6711.\n2 Spring      90             17910.            8357.\n3 Summer      92             24818.            7297.\n4 Winter      90              5413.            1808.\n\n\nLet’s analyze this data in detail We can check the correlation between numeric columns We can plot the graphs of day rental vs seasons\n\n# 1. Basic Summary Statistics\ncat(\"Basic Summary Statistics:\\n\")\n\nBasic Summary Statistics:\n\nsummary(daily_bike_data)\n\n      date              seasons         holiday     total_bikes   \n Min.   :2017-12-01   Autumn:81   Holiday   : 17   Min.   :  977  \n 1st Qu.:2018-02-27   Spring:90   No Holiday:336   1st Qu.: 6967  \n Median :2018-05-28   Summer:92                    Median :18563  \n Mean   :2018-05-28   Winter:90                    Mean   :17485  \n 3rd Qu.:2018-08-24                                3rd Qu.:26285  \n Max.   :2018-11-30                                Max.   :36149  \n total_rainfall   total_snowfall     mean_temp       mean_humidity  \n Min.   : 0.000   Min.   : 0.000   Min.   :-14.738   Min.   :22.25  \n 1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.:  3.304   1st Qu.:47.58  \n Median : 0.000   Median : 0.000   Median : 13.738   Median :57.17  \n Mean   : 3.576   Mean   : 1.863   Mean   : 12.776   Mean   :58.17  \n 3rd Qu.: 0.500   3rd Qu.: 0.000   3rd Qu.: 22.592   3rd Qu.:67.71  \n Max.   :95.500   Max.   :78.700   Max.   : 33.742   Max.   :95.88  \n mean_wind_speed  mean_visibility  mean_dew_point    mean_solar_rad   \n Min.   :0.6625   Min.   : 214.3   Min.   :-27.750   Min.   :0.02917  \n 1st Qu.:1.3042   1st Qu.:1087.0   1st Qu.: -5.188   1st Qu.:0.28333  \n Median :1.6583   Median :1557.8   Median :  4.612   Median :0.56500  \n Mean   :1.7261   Mean   :1434.0   Mean   :  3.954   Mean   :0.56773  \n 3rd Qu.:1.9542   3rd Qu.:1874.3   3rd Qu.: 14.921   3rd Qu.:0.82000  \n Max.   :4.0000   Max.   :2000.0   Max.   : 25.038   Max.   :1.21667  \n\n# 2. Summary by Season\ncat(\"\\nSummary by Season:\\n\")\n\n\nSummary by Season:\n\ndaily_bike_data %&gt;%\n  group_by(seasons) %&gt;%\n  summarise(\n    n_days = n(),\n    mean_rentals = mean(total_bikes),\n    sd_rentals = sd(total_bikes),\n    min_rentals = min(total_bikes),\n    max_rentals = max(total_bikes)\n  )\n\n# A tibble: 4 × 6\n  seasons n_days mean_rentals sd_rentals min_rentals max_rentals\n  &lt;fct&gt;    &lt;int&gt;        &lt;dbl&gt;      &lt;dbl&gt;       &lt;int&gt;       &lt;int&gt;\n1 Autumn      81       22099.      6711.        1721       31809\n2 Spring      90       17910.      8357.         977       31681\n3 Summer      92       24818.      7297.        3231       36149\n4 Winter      90        5413.      1808.        2014        9539\n\n# 3. Summary by Holiday Status\ncat(\"\\nSummary by Holiday Status:\\n\")\n\n\nSummary by Holiday Status:\n\ndaily_bike_data %&gt;%\n  group_by(holiday) %&gt;%\n  summarise(\n    n_days = n(),\n    mean_rentals = mean(total_bikes),\n    sd_rentals = sd(total_bikes),\n    min_rentals = min(total_bikes),\n    max_rentals = max(total_bikes)\n  )\n\n# A tibble: 2 × 6\n  holiday    n_days mean_rentals sd_rentals min_rentals max_rentals\n  &lt;fct&gt;       &lt;int&gt;        &lt;dbl&gt;      &lt;dbl&gt;       &lt;int&gt;       &lt;int&gt;\n1 Holiday        17       12700.     10504.        2014       30498\n2 No Holiday    336       17727.      9862.         977       36149\n\n# 4. Correlation Analysis\n# Select numeric columns\nnumeric_cols &lt;- daily_bike_data %&gt;%\n  select(total_bikes, total_rainfall, total_snowfall, \n         mean_temp, mean_humidity, mean_wind_speed, \n         mean_visibility, mean_dew_point, mean_solar_rad)\n\n# Calculate correlations\ncorrelations &lt;- cor(numeric_cols)\n\n# Print correlations with total_bikes\ncat(\"\\nCorrelations with total_bikes:\\n\")\n\n\nCorrelations with total_bikes:\n\nsort(correlations[1,], decreasing = TRUE)\n\n    total_bikes       mean_temp  mean_solar_rad  mean_dew_point mean_visibility \n     1.00000000      0.75307673      0.73589290      0.65047655      0.16599375 \n  mean_humidity mean_wind_speed  total_rainfall  total_snowfall \n     0.03588697     -0.19288142     -0.23910905     -0.26529110 \n\n# 5. Create plots\nlibrary(ggplot2)\n\n# Plot 1: Daily rentals over time\nggplot(daily_bike_data, aes(x = date, y = total_bikes)) +\n  geom_line() +\n  labs(title = \"Daily Bike Rentals Over Time\",\n       x = \"Date\",\n       y = \"Total Rentals\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Plot 2: Box plot of rentals by season\nggplot(daily_bike_data, aes(x = seasons, y = total_bikes, fill = seasons)) +\n  geom_boxplot() +\n  labs(title = \"Bike Rentals by Season\",\n       x = \"Season\",\n       y = \"Total Rentals\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Plot 3: Scatter plot of temperature vs rentals\nggplot(daily_bike_data, aes(x = mean_temp, y = total_bikes)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  labs(title = \"Temperature vs Bike Rentals\",\n       x = \"Mean Temperature (°C)\",\n       y = \"Total Rentals\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Plot 4: Rentals vs rainfall\nggplot(daily_bike_data, aes(x = total_rainfall, y = total_bikes)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  labs(title = \"Rainfall vs Bike Rentals\",\n       x = \"Total Rainfall (mm)\",\n       y = \"Total Rentals\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nSplit the Data\n• Use functions from tidymodels to split the data into a training and test set (75/25 split). Use the strata argument to stratify the split on the seasons variable. • On the training set, create a 10 fold CV split\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Create initial split (75/25) stratified by seasons\nbike_split &lt;- initial_split(daily_bike_data, prop = 0.75, strata = seasons)\n\n# Create training and testing sets\nbike_train &lt;- training(bike_split)\nbike_test &lt;- testing(bike_split)\n\n# Create 10-fold CV split on training data\nbike_folds &lt;- vfold_cv(bike_train, v = 10, strata = seasons)\n\n# Check the dimensions of our splits\ncat(\"Dimensions of datasets:\\n\")\n\nDimensions of datasets:\n\ncat(\"Full data:\", nrow(daily_bike_data), \"rows\\n\")\n\nFull data: 353 rows\n\ncat(\"Training set:\", nrow(bike_train), \"rows\\n\")\n\nTraining set: 263 rows\n\ncat(\"Testing set:\", nrow(bike_test), \"rows\\n\")\n\nTesting set: 90 rows\n\n# Verify stratification by checking proportion of seasons in each set\ncat(\"\\nProportion of seasons in full dataset:\\n\")\n\n\nProportion of seasons in full dataset:\n\nprop.table(table(daily_bike_data$seasons))\n\n\n   Autumn    Spring    Summer    Winter \n0.2294618 0.2549575 0.2606232 0.2549575 \n\ncat(\"\\nProportion of seasons in training set:\\n\")\n\n\nProportion of seasons in training set:\n\nprop.table(table(bike_train$seasons))\n\n\n   Autumn    Spring    Summer    Winter \n0.2281369 0.2547529 0.2623574 0.2547529 \n\ncat(\"\\nProportion of seasons in testing set:\\n\")\n\n\nProportion of seasons in testing set:\n\nprop.table(table(bike_test$seasons))\n\n\n   Autumn    Spring    Summer    Winter \n0.2333333 0.2555556 0.2555556 0.2555556 \n\n# Check the structure of the CV folds\nbike_folds\n\n#  10-fold cross-validation using stratification \n# A tibble: 10 × 2\n   splits           id    \n   &lt;list&gt;           &lt;chr&gt; \n 1 &lt;split [236/27]&gt; Fold01\n 2 &lt;split [236/27]&gt; Fold02\n 3 &lt;split [236/27]&gt; Fold03\n 4 &lt;split [236/27]&gt; Fold04\n 5 &lt;split [236/27]&gt; Fold05\n 6 &lt;split [236/27]&gt; Fold06\n 7 &lt;split [236/27]&gt; Fold07\n 8 &lt;split [238/25]&gt; Fold08\n 9 &lt;split [238/25]&gt; Fold09\n10 &lt;split [239/24]&gt; Fold10"
  },
  {
    "objectID": "homework8.html#fitting-mlr-models",
    "href": "homework8.html#fitting-mlr-models",
    "title": "HomeWork8",
    "section": "Fitting MLR Models",
    "text": "Fitting MLR Models\nFirst, let’s create some recipes. For the 1st recipe: • Let’s ignore the date variable for modeling (so we’ll need to remove that or give it a different ID) but use it to create a weekday/weekend (factor) variable. (See step 2 of the shinymodels tutorial! You can use step_date() then step_mutate() with a factor(if_else(…)) to create the variable. I then had to remove the intermediate variable created.) • Let’s standardize the numeric variables since their scales are pretty different. • Let’s create dummy variables for the seasons, holiday, and our new day type variable\n\n# Create first recipe\nrecipe1 &lt;- recipe(total_bikes ~ ., data = bike_train) %&gt;%\n # Create weekday/weekend variable from date\n step_date(date, features = \"dow\") %&gt;%\n step_mutate(\n   day_type = factor(if_else(\n     date_dow %in% c(\"Sat\", \"Sun\"), \n     \"weekend\", \n     \"weekday\"\n   ))\n ) %&gt;%\n # Remove the intermediate dow variable and date\n step_rm(date_dow, date) %&gt;%\n # Standardize numeric variables\n step_normalize(all_numeric_predictors()) %&gt;%\n # Create dummy variables\n step_dummy(all_nominal_predictors())\n\n# Print the recipe to check steps\nprint(recipe1)\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 11\n\n\n\n\n\n── Operations \n\n\n• Date features from: date\n\n\n• Variable mutation for: factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"),\n  \"weekend\", \"weekday\"))\n\n\n• Variables removed: date_dow and date\n\n\n• Centering and scaling for: all_numeric_predictors()\n\n\n• Dummy variables from: all_nominal_predictors()\n\n# Check if recipe works by prepping it\nprep(recipe1) %&gt;%\n bake(new_data = NULL) %&gt;%\n glimpse()\n\nRows: 263\nColumns: 14\n$ total_rainfall     &lt;dbl&gt; -0.2970185, -0.2970185, -0.1773679, -0.2970185, -0.…\n$ total_snowfall     &lt;dbl&gt; -0.2179228, -0.2179228, -0.2179228, -0.2179228, -0.…\n$ mean_temp          &lt;dbl&gt; 0.942813132, 0.977863864, 0.800131869, 0.760478516,…\n$ mean_humidity      &lt;dbl&gt; 0.21420205, 0.81794255, -0.11561916, -0.66625286, -…\n$ mean_wind_speed    &lt;dbl&gt; 1.32331031, 0.28870706, 1.28079237, -0.10104074, -0…\n$ mean_visibility    &lt;dbl&gt; 1.05187245, 0.41451440, 0.84111295, 1.10774745, 1.1…\n$ mean_dew_point     &lt;dbl&gt; 0.87630133, 1.09270791, 0.66181269, 0.44380783, 0.4…\n$ mean_solar_rad     &lt;dbl&gt; 1.17578189, -0.32588618, 0.79740883, 1.21388195, 1.…\n$ total_bikes        &lt;int&gt; 31114, 27838, 30381, 29813, 28354, 30781, 31809, 30…\n$ seasons_Spring     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ seasons_Summer     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ seasons_Winter     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ holiday_No.Holiday &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, …\n$ day_type_weekend   &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, …\n\n\nFor the 2nd recipe: • Do the same steps as above. • Add in interactions between seasons and holiday, seasons and temp, temp and rainfall. For the seasons interactions, you can use starts_with() to create the proper interactions.\n\n# Create second recipe\nrecipe2 &lt;- recipe(total_bikes ~ ., data = bike_train) %&gt;%\n  step_date(date, features = \"dow\") %&gt;%\n  step_mutate(\n    day_type = factor(if_else(\n      date_dow %in% c(\"Sat\", \"Sun\"), \n      \"weekend\", \n      \"weekday\"\n    ))\n  ) %&gt;%\n  step_rm(date_dow, date) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%\n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %&gt;%  # Changed to one_hot encoding\n  # Simplified interactions\n  step_interact(terms = ~ mean_temp:total_rainfall)%&gt;%\n  # Handle rank deficiency\n  step_zv(all_predictors())\n\n# Print the recipe to check steps\nprint(recipe2)\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 11\n\n\n\n\n\n── Operations \n\n\n• Date features from: date\n\n\n• Variable mutation for: factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"),\n  \"weekend\", \"weekday\"))\n\n\n• Variables removed: date_dow and date\n\n\n• Centering and scaling for: all_numeric_predictors()\n\n\n• Dummy variables from: all_nominal_predictors()\n\n\n• Interactions with: mean_temp:total_rainfall\n\n\n• Zero variance filter on: all_predictors()\n\n# Check if recipe works and examine the results\nprep(recipe2) %&gt;%\n bake(new_data = NULL) %&gt;%\n glimpse()\n\nRows: 263\nColumns: 18\n$ total_rainfall             &lt;dbl&gt; -0.2970185, -0.2970185, -0.1773679, -0.2970…\n$ total_snowfall             &lt;dbl&gt; -0.2179228, -0.2179228, -0.2179228, -0.2179…\n$ mean_temp                  &lt;dbl&gt; 0.942813132, 0.977863864, 0.800131869, 0.76…\n$ mean_humidity              &lt;dbl&gt; 0.21420205, 0.81794255, -0.11561916, -0.666…\n$ mean_wind_speed            &lt;dbl&gt; 1.32331031, 0.28870706, 1.28079237, -0.1010…\n$ mean_visibility            &lt;dbl&gt; 1.05187245, 0.41451440, 0.84111295, 1.10774…\n$ mean_dew_point             &lt;dbl&gt; 0.87630133, 1.09270791, 0.66181269, 0.44380…\n$ mean_solar_rad             &lt;dbl&gt; 1.17578189, -0.32588618, 0.79740883, 1.2138…\n$ total_bikes                &lt;int&gt; 31114, 27838, 30381, 29813, 28354, 30781, 3…\n$ seasons_Autumn             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ seasons_Spring             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ seasons_Summer             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ seasons_Winter             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ holiday_Holiday            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ holiday_No.Holiday         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day_type_weekday           &lt;dbl&gt; 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0…\n$ day_type_weekend           &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1…\n$ mean_temp_x_total_rainfall &lt;dbl&gt; -0.280032902, -0.290443616, -0.141917717, -…\n\n# Check names of interaction terms\nprocessed_data2 &lt;- prep(recipe2) %&gt;%\n bake(new_data = NULL)\n\ncat(\"\\nInteraction terms created:\\n\")\n\n\nInteraction terms created:\n\nnames(processed_data2)[grep(\"_x_\", names(processed_data2))]\n\n[1] \"mean_temp_x_total_rainfall\"\n\n\nThis recipe includes:\nAll transformations from recipe1 Interactions between:\n\nSeasons dummy variables and holiday\nSeasons dummy variables and mean temperature\nMean temperature and total rainfall\n\nFor the 3rd recipe: • Do the same as the 2nd recipe. • Add in quadratic terms for each numeric predictor\n\n# Create third recipe\nrecipe3 &lt;- recipe(total_bikes ~ ., data = bike_train) %&gt;%\n  step_date(date, features = \"dow\") %&gt;%\n  step_mutate(\n    day_type = factor(if_else(\n      date_dow %in% c(\"Sat\", \"Sun\"), \n      \"weekend\", \n      \"weekday\"\n    ))\n  ) %&gt;%\n  step_rm(date_dow, date) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%\n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %&gt;%  # Changed to one_hot encoding\n  step_interact(terms = ~ mean_temp:total_rainfall) %&gt;%\n  # More selective with polynomial terms\n  step_poly(mean_temp, mean_humidity, mean_wind_speed, degree = 2)\n\n# Print the recipe to check steps\nprint(recipe3)\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 11\n\n\n\n\n\n── Operations \n\n\n• Date features from: date\n\n\n• Variable mutation for: factor(if_else(date_dow %in% c(\"Sat\", \"Sun\"),\n  \"weekend\", \"weekday\"))\n\n\n• Variables removed: date_dow and date\n\n\n• Centering and scaling for: all_numeric_predictors()\n\n\n• Dummy variables from: all_nominal_predictors()\n\n\n• Interactions with: mean_temp:total_rainfall\n\n\n• Orthogonal polynomials on: mean_temp, mean_humidity, mean_wind_speed\n\n# Check if recipe works and examine the results\nprocessed_data3 &lt;- prep(recipe3) %&gt;%\n bake(new_data = NULL)\n\n# Look at the structure\nglimpse(processed_data3)\n\nRows: 263\nColumns: 21\n$ total_rainfall             &lt;dbl&gt; -0.2970185, -0.2970185, -0.1773679, -0.2970…\n$ total_snowfall             &lt;dbl&gt; -0.2179228, -0.2179228, -0.2179228, -0.2179…\n$ mean_visibility            &lt;dbl&gt; 1.05187245, 0.41451440, 0.84111295, 1.10774…\n$ mean_dew_point             &lt;dbl&gt; 0.87630133, 1.09270791, 0.66181269, 0.44380…\n$ mean_solar_rad             &lt;dbl&gt; 1.17578189, -0.32588618, 0.79740883, 1.2138…\n$ total_bikes                &lt;int&gt; 31114, 27838, 30381, 29813, 28354, 30781, 3…\n$ seasons_Autumn             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ seasons_Spring             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ seasons_Summer             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ seasons_Winter             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ holiday_Holiday            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ holiday_No.Holiday         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day_type_weekday           &lt;dbl&gt; 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0…\n$ day_type_weekend           &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1…\n$ mean_temp_x_total_rainfall &lt;dbl&gt; -0.280032902, -0.290443616, -0.141917717, -…\n$ mean_temp_poly_1           &lt;dbl&gt; 0.0582471898, 0.0604126312, 0.0494323119, 0…\n$ mean_temp_poly_2           &lt;dbl&gt; 4.343638e-03, 8.936806e-03, -1.277782e-02, …\n$ mean_humidity_poly_1       &lt;dbl&gt; 0.013233447, 0.050532660, -0.007142975, -0.…\n$ mean_humidity_poly_2       &lt;dbl&gt; -0.049710700, -0.025703529, -0.047520174, -…\n$ mean_wind_speed_poly_1     &lt;dbl&gt; 0.081754384, 0.017836382, 0.079127617, -0.0…\n$ mean_wind_speed_poly_2     &lt;dbl&gt; -0.022889314, -0.051814842, -0.025910870, -…\n\n# Check names of quadratic terms\ncat(\"\\nQuadratic terms created:\\n\")\n\n\nQuadratic terms created:\n\nnames(processed_data3)[grep(\"_2$\", names(processed_data3))]\n\n[1] \"mean_temp_poly_2\"       \"mean_humidity_poly_2\"   \"mean_wind_speed_poly_2\"\n\n\nThis recipe includes:\nAll transformations from recipe2 Quadratic terms (squared terms) for all numeric predictors:\ntotal_rainfall mean_temp mean_humidity mean_wind_speed mean_visibility mean_dew_point mean_solar_rad total_snowfall\nEach numeric variable will now have both its linear and quadratic term, allowing for curved relationships with the response variable.\nNow set up our linear model fit to use the “lm” engine. Fit the models using 10 fold CV via fit_resamples() and consider the training set CV error to choose a best model.\n\n# Set up linear model with lm engine\nlm_model &lt;- linear_reg() %&gt;%\n set_engine(\"lm\")\n\n# Create workflows for each recipe\nworkflow1 &lt;- workflow() %&gt;%\n add_recipe(recipe1) %&gt;%\n add_model(lm_model)\n\nworkflow2 &lt;- workflow() %&gt;%\n add_recipe(recipe2) %&gt;%\n add_model(lm_model)\n\nworkflow3 &lt;- workflow() %&gt;%\n add_recipe(recipe3) %&gt;%\n add_model(lm_model)\n\n# Fit models using 10-fold CV\nset.seed(123)  # for reproducibility\n\n# Fit model 1\ncv_results1 &lt;- workflow1 %&gt;%\n fit_resamples(\n   resamples = bike_folds,\n   metrics = metric_set(rmse, rsq, mae)\n )\n\n# Fit model 2\ncv_results2 &lt;- workflow2 %&gt;%\n fit_resamples(\n   resamples = bike_folds,\n   metrics = metric_set(rmse, rsq, mae),\n   control = control_resamples(save_pred = TRUE)\n )\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x10\n\n\n\n\n# Fit model 3\ncv_results3 &lt;- workflow3 %&gt;%\n fit_resamples(\n   resamples = bike_folds,\n   metrics = metric_set(rmse, rsq, mae),\n   control = control_resamples(save_pred = TRUE)\n )\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n# Collect and compare CV results\ncat(\"Model 1 CV Results:\\n\")\n\nModel 1 CV Results:\n\ncollect_metrics(cv_results1)\n\n# A tibble: 3 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   3188.       10 130.     Preprocessor1_Model1\n2 rmse    standard   4151.       10 150.     Preprocessor1_Model1\n3 rsq     standard      0.825    10   0.0138 Preprocessor1_Model1\n\ncat(\"\\nModel 2 CV Results:\\n\")\n\n\nModel 2 CV Results:\n\ncollect_metrics(cv_results2)\n\n# A tibble: 3 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   3210.       10 130.     Preprocessor1_Model1\n2 rmse    standard   4179.       10 146.     Preprocessor1_Model1\n3 rsq     standard      0.823    10   0.0133 Preprocessor1_Model1\n\ncat(\"\\nModel 3 CV Results:\\n\")\n\n\nModel 3 CV Results:\n\ncollect_metrics(cv_results3)\n\n# A tibble: 3 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 mae     standard   3057.       10 155.     Preprocessor1_Model1\n2 rmse    standard   3870.       10 176.     Preprocessor1_Model1\n3 rsq     standard      0.850    10   0.0141 Preprocessor1_Model1\n\n# Compare models side by side\n\ncombined_results &lt;- bind_rows(\n  collect_metrics(cv_results1) %&gt;% mutate(model = \"Model 1\"),\n  collect_metrics(cv_results2) %&gt;% mutate(model = \"Model 2\"),\n  collect_metrics(cv_results3) %&gt;% mutate(model = \"Model 3\")\n)\n\n# Calculate the mean of each metric for each model\nmodel_comparison &lt;- combined_results %&gt;%\n  group_by(model, .metric) %&gt;%\n  summarise(mean = mean(mean, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = .metric, values_from = mean) %&gt;%\n  select(model, mae, rmse, rsq)\n\n`summarise()` has grouped output by 'model'. You can override using the\n`.groups` argument.\n\n# Print the model comparison\nprint(model_comparison)\n\n# A tibble: 3 × 4\n  model     mae  rmse   rsq\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Model 1 3188. 4151. 0.825\n2 Model 2 3210. 4179. 0.823\n3 Model 3 3057. 3870. 0.850\n\n\nBased on the cross-validation results:\nModel 3 has the lowest Mean Absolute Error (MAE) of 3057.225, indicating that, on average, the predicted values deviate from the actual values by approximately 3057.225 units. Lower MAE values are generally preferred. Model 3 also has the lowest Root Mean Squared Error (RMSE) of 3869.794, suggesting that it has the smallest average magnitude of the residuals (prediction errors). RMSE is more sensitive to large errors compared to MAE. Model 3 has the highest R-squared value of 0.8504317, indicating that approximately 85.04% of the variance in the target variable can be explained by the predictors in Model 3. Higher R-squared values indicate better model fit.\nConsidering all three metrics, Model 3 appears to have the best performance among the three models. It has the lowest MAE and RMSE, suggesting better predictive accuracy, and the highest R-squared value, indicating a better fit to the data\nTo fit Model 3 on the entire training set, compute the test set RMSE, and extract the model coefficients\n\n# Fit best model on entire dataset\nfinal_fit &lt;- last_fit(\n  workflow3,  \n  split = bike_split,\n  metrics = metric_set(rmse, rsq)\n)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\n# Extract test metrics\ncollect_metrics(final_fit)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    3822.    Preprocessor1_Model1\n2 rsq     standard       0.858 Preprocessor1_Model1\n\n# Extract coefficients\nfinal_coef &lt;- final_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  tidy()\n\nprint(\"Final model coefficients:\")\n\n[1] \"Final model coefficients:\"\n\nprint(final_coef)\n\n# A tibble: 21 × 5\n   term            estimate std.error statistic   p.value\n   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)      13921.       979.    14.2    7.21e-34\n 2 total_rainfall   -2152.       566.    -3.80   1.80e- 4\n 3 total_snowfall      34.8      263.     0.132  8.95e- 1\n 4 mean_visibility    360.       335.     1.07   2.83e- 1\n 5 mean_dew_point   17685.      5792.     3.05   2.51e- 3\n 6 mean_solar_rad    4088.       439.     9.32   7.30e-18\n 7 seasons_Autumn    4974.      1131.     4.40   1.62e- 5\n 8 seasons_Spring    -592.      1155.    -0.512  6.09e- 1\n 9 seasons_Summer    3268.      1526.     2.14   3.32e- 2\n10 seasons_Winter      NA         NA     NA     NA       \n# ℹ 11 more rows\n\n\nThe model coefficients provide valuable insights into how each predictor affects the total number of bikes, holding all other predictors constant. Here are some key takeaways:\nIntercept: The intercept represents the predicted number of bikes when all predictors are zero (for standardized numeric predictors) or at their reference level (for categorical predictors). In this case, the intercept is 13921.39 bikes. Weather variables:\ntotal_rainfall: A one standard deviation increase in total rainfall is associated with a decrease of 2151.76 bikes, on average. This effect is statistically significant (p &lt; 0.001). mean_solar_rad: A one standard deviation increase in mean solar radiation is associated with an increase of 4087.83 bikes, on average. This effect is highly statistically significant (p &lt; 0.001). mean_dew_point: A one standard deviation increase in mean dew point is associated with an increase of 17685.19 bikes, on average. This effect is statistically significant (p &lt; 0.01).\nSeasonal and day type effects:\nCompared to Winter (the reference level), Autumn is associated with an increase of 4974.21 bikes (p &lt; 0.001), while Summer is associated with an increase of 3268.20 bikes (p &lt; 0.05). The effect of Spring is not statistically significant. Weekdays are associated with an increase of 2364.97 bikes compared to weekends (p &lt; 0.001).\nInteraction and polynomial terms:\nThe interaction between mean temperature and total rainfall is not statistically significant. The quadratic terms for mean temperature and mean humidity are statistically significant (p &lt; 0.001 and p &lt; 0.05, respectively), indicating a non-linear relationship between these predictors and the total number of bikes.\nNon-significant predictors:\ntotal_snowfall, mean_visibility, and the polynomial terms for mean_wind_speed are not statistically significant, suggesting they may not be important predictors of the total number of bikes in this model."
  }
]